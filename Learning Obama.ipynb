{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split,cross_val_score, KFold,cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5624\n",
      "5600\n"
     ]
    }
   ],
   "source": [
    "obamaData = pd.read_csv(\"obamaCleanedData.csv\")\n",
    "print(len(obamaData))\n",
    "obamaData.dropna(axis=0,inplace=True)\n",
    "print(len(obamaData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.8214285714\n",
      "10-fold: [59.642857142857146, 60.178571428571431, 57.321428571428569, 60.178571428571431, 59.285714285714285, 56.607142857142854, 59.464285714285715, 59.821428571428569, 60.714285714285715, 55.0]\n",
      "Precision: [ 0.56664113  0.59764883  0.6117596 ]\n",
      "Recall: [ 0.70950782  0.43947822  0.62050612]\n",
      "Confusion matrix:\n",
      "[[1397  332  239]\n",
      " [ 687  866  417]\n",
      " [ 381  250 1031]]\n",
      "F-Score: [ 0.62978161  0.50553055  0.61549503]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf_nb = MultinomialNB()\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "k_fold = KFold(n=len(obamaData), n_folds=10)\n",
    "scores = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "confusion = np.array([[0, 0, 0],[0, 0, 0], [0, 0, 0]])\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = obamaData.iloc[train_indices]['tweet'].values\n",
    "    train_y = obamaData.iloc[train_indices]['label'].values\n",
    "\n",
    "    test_text = obamaData.iloc[test_indices]['tweet'].values\n",
    "    test_y = np.asarray(obamaData.iloc[test_indices]['label'].values, dtype=\"|S6\")\n",
    "\n",
    "    counts = count_vectorizer.fit_transform(train_text)\n",
    "    targets = np.asarray(train_y, dtype=\"|S6\")\n",
    "    clf_nb.fit(counts, targets)\n",
    "    predictions = clf_nb.predict(count_vectorizer.transform(test_text))\n",
    "\n",
    "    confusion+= confusion_matrix(test_y, predictions)\n",
    "    p=precision_score(test_y, predictions, average=None)\n",
    "    r=recall_score(test_y, predictions, average=None)\n",
    "    score = 2*p*r/(p+r)\n",
    "    scores.append(score)\n",
    "    accuracy.append((predictions==test_y).sum()*100/float(len(test_y)))\n",
    "    precision.append(p)  \n",
    "    recall.append(r)  \n",
    "\n",
    "print('Accuracy:', sum(accuracy)/len(accuracy))\n",
    "print('10-fold:', accuracy)\n",
    "print('Precision:', sum(precision)/len(precision))\n",
    "print('Recall:', sum(recall)/len(recall))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)\n",
    "print('F-Score:', sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.5178571429\n",
      "10-fold: [58.392857142857146, 61.071428571428569, 57.142857142857146, 58.75, 58.392857142857146, 55.535714285714285, 60.714285714285715, 60.535714285714285, 58.571428571428569, 56.071428571428569]\n",
      "Precision: [ 0.60942869  0.54434097  0.60740664]\n",
      "Recall: [ 0.58910866  0.5589335   0.61058372]\n",
      "Confusion matrix:\n",
      "[[1161  533  274]\n",
      " [ 488 1101  381]\n",
      " [ 257  390 1015]]\n",
      "F-Score: [ 0.59846812  0.55064503  0.60873694]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:561: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_nn_MLP = MLPClassifier(solver='sgd', alpha=0.001,hidden_layer_sizes=(50, 10), learning_rate = 'adaptive', random_state=42,activation='tanh')\n",
    "\n",
    "k_fold = KFold(n=len(obamaData), n_folds=10)\n",
    "scores = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "confusion = np.array([[0, 0, 0],[0, 0, 0], [0, 0, 0]])\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = obamaData.iloc[train_indices]['tweet'].values\n",
    "    train_y = obamaData.iloc[train_indices]['label'].values\n",
    "\n",
    "    test_text = obamaData.iloc[test_indices]['tweet'].values\n",
    "    test_y = np.asarray(obamaData.iloc[test_indices]['label'].values, dtype=\"|S6\")\n",
    "\n",
    "    counts = count_vectorizer.fit_transform(train_text)\n",
    "    targets = np.asarray(train_y, dtype=\"|S6\")\n",
    "    clf_nn_MLP.fit(counts, targets)\n",
    "    predictions = clf_nn_MLP.predict(count_vectorizer.transform(test_text))\n",
    "\n",
    "    confusion+= confusion_matrix(test_y, predictions)\n",
    "    p=precision_score(test_y, predictions, average=None)\n",
    "    r=recall_score(test_y, predictions, average=None)\n",
    "    score = 2*p*r/(p+r)\n",
    "    scores.append(score)\n",
    "    accuracy.append((predictions==test_y).sum()*100/float(len(test_y)))\n",
    "    precision.append(p)  \n",
    "    recall.append(r)  \n",
    "\n",
    "print('Accuracy:', sum(accuracy)/len(accuracy))\n",
    "print('10-fold:', accuracy)\n",
    "print('Precision:', sum(precision)/len(precision))\n",
    "print('Recall:', sum(recall)/len(recall))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)\n",
    "print('F-Score:', sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.8928571429\n",
      "10-fold: [58.214285714285715, 54.285714285714285, 56.071428571428569, 63.571428571428569, 56.428571428571431, 54.285714285714285, 55.357142857142854, 55.178571428571431, 58.75, 56.785714285714285]\n",
      "Precision: [ 0.58125928  0.53674571  0.59161975]\n",
      "Recall: [ 0.58563363  0.53299897  0.59017593]\n",
      "Confusion matrix:\n",
      "[[1154  544  270]\n",
      " [ 510 1052  408]\n",
      " [ 324  358  980]]\n",
      "F-Score: [ 0.5829062   0.53454612  0.59050181]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rfc = RandomForestClassifier(n_estimators=22,class_weight=\"balanced_subsample\")\n",
    "count_vectorizer_rfc = CountVectorizer()\n",
    "# tfidf_transformer_rfc = TfidfTransformer()\n",
    "\n",
    "k_fold = KFold(n=len(obamaData), n_folds=10)\n",
    "scores = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "confusion = np.array([[0, 0, 0],[0, 0, 0], [0, 0, 0]])\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = obamaData.iloc[train_indices]['tweet'].values\n",
    "    train_y = obamaData.iloc[train_indices]['label'].values\n",
    "\n",
    "    test_text = obamaData.iloc[test_indices]['tweet'].values\n",
    "    test_y = np.asarray(obamaData.iloc[test_indices]['label'].values, dtype=\"|S6\")\n",
    "\n",
    "    counts_rfc = count_vectorizer_rfc.fit_transform(train_text)\n",
    "#     tfidf_vector_rfc = tfidf_transformer_rfc.fit_transform(counts_rfc)\n",
    "    targets = np.asarray(train_y, dtype=\"|S6\")\n",
    "    \n",
    "    clf_rfc.fit(counts_rfc, targets)\n",
    "    test_counts_rfc = count_vectorizer_rfc.transform(test_text)\n",
    "#     test_tfidf_vector_rfc = tfidf_transformer_rfc.transform(test_counts_rfc)\n",
    "    predictions = clf_rfc.predict(test_counts_rfc)\n",
    "\n",
    "    confusion+= confusion_matrix(test_y, predictions)\n",
    "    p=precision_score(test_y, predictions, average=None)\n",
    "    r=recall_score(test_y, predictions, average=None)\n",
    "    score = 2*p*r/(p+r)\n",
    "    scores.append(score)\n",
    "    accuracy.append((predictions==test_y).sum()*100/float(len(test_y)))\n",
    "    precision.append(p)  \n",
    "    recall.append(r)  \n",
    "\n",
    "print('Accuracy:', sum(accuracy)/len(accuracy))\n",
    "print('10-fold:', accuracy)\n",
    "print('Precision:', sum(precision)/len(precision))\n",
    "print('Recall:', sum(recall)/len(recall))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)\n",
    "print('F-Score:', sum(scores)/len(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.0178571429\n",
      "10-fold: [57.5, 58.75, 54.821428571428569, 58.75, 56.607142857142854, 55.892857142857146, 59.285714285714285, 56.071428571428569, 56.964285714285715, 55.535714285714285]\n",
      "Precision: [ 0.60145028  0.53859439  0.5705095 ]\n",
      "Recall: [ 0.57897286  0.50695298  0.63418008]\n",
      "Confusion matrix:\n",
      "[[1141  501  326]\n",
      " [ 503  998  469]\n",
      " [ 253  355 1054]]\n",
      "F-Score: [ 0.58951163  0.52140563  0.60006204]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf_svc = LinearSVC(C=0.5,loss=\"hinge\",multi_class=\"ovr\",penalty=\"l2\")\n",
    "\n",
    "k_fold = KFold(n=len(obamaData), n_folds=10)\n",
    "scores = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "confusion = np.array([[0, 0, 0],[0, 0, 0], [0, 0, 0]])\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = obamaData.iloc[train_indices]['tweet'].values\n",
    "    train_y = obamaData.iloc[train_indices]['label'].values\n",
    "\n",
    "    test_text = obamaData.iloc[test_indices]['tweet'].values\n",
    "    test_y = np.asarray(obamaData.iloc[test_indices]['label'].values, dtype=\"|S6\")\n",
    "\n",
    "    counts = count_vectorizer.fit_transform(train_text)\n",
    "    targets = np.asarray(train_y, dtype=\"|S6\")\n",
    "    clf_svc.fit(counts, targets)\n",
    "    predictions = clf_svc.predict(count_vectorizer.transform(test_text))\n",
    "\n",
    "    confusion+= confusion_matrix(test_y, predictions)\n",
    "    p=precision_score(test_y, predictions, average=None)\n",
    "    r=recall_score(test_y, predictions, average=None)\n",
    "    score = 2*p*r/(p+r)\n",
    "    scores.append(score)\n",
    "    accuracy.append((predictions==test_y).sum()*100/float(len(test_y)))\n",
    "    precision.append(p)  \n",
    "    recall.append(r)  \n",
    "\n",
    "print('Accuracy:', sum(accuracy)/len(accuracy))\n",
    "print('10-fold:', accuracy)\n",
    "print('Precision:', sum(precision)/len(precision))\n",
    "print('Recall:', sum(recall)/len(recall))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)\n",
    "print('F-Score:', sum(scores)/len(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier - Naive Bayes, Neural Network, Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.6071428571\n",
      "10-fold: [60.892857142857146, 61.25, 58.214285714285715, 62.678571428571431, 60.0, 60.535714285714285, 63.035714285714285, 61.25, 62.142857142857146, 56.071428571428569]\n",
      "Precision: [ 0.60802957  0.58843891  0.62194957]\n",
      "Recall: [ 0.67296533  0.51257117  0.63783069]\n",
      "Confusion matrix:\n",
      "[[1325  397  246]\n",
      " [ 563 1009  398]\n",
      " [ 293  309 1060]]\n",
      "F-Score: [ 0.63844683  0.54692454  0.62928028]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "clf_voting = VotingClassifier(estimators=[('mnb', clf_nb), ('nn_mlp', clf_nn_MLP), ('rfc', clf_rfc)],\n",
    "                              voting='soft',n_jobs=-1)\n",
    "\n",
    "k_fold = KFold(n=len(obamaData), n_folds=10)\n",
    "scores = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "confusion = np.array([[0, 0, 0],[0, 0, 0], [0, 0, 0]])\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = obamaData.iloc[train_indices]['tweet'].values\n",
    "    train_y = obamaData.iloc[train_indices]['label'].values\n",
    "\n",
    "    test_text = obamaData.iloc[test_indices]['tweet'].values\n",
    "    test_y = np.asarray(obamaData.iloc[test_indices]['label'].values, dtype=\"|S6\")\n",
    "\n",
    "    counts = count_vectorizer.fit_transform(train_text)\n",
    "    targets = np.asarray(train_y, dtype=\"|S6\")\n",
    "    clf_voting.fit(counts, targets)\n",
    "    predictions = clf_voting.predict(count_vectorizer.transform(test_text))\n",
    "\n",
    "    confusion+= confusion_matrix(test_y, predictions)\n",
    "    p=precision_score(test_y, predictions, average=None)\n",
    "    r=recall_score(test_y, predictions, average=None)\n",
    "    score = 2*p*r/(p+r)\n",
    "    scores.append(score)\n",
    "    accuracy.append((predictions==test_y).sum()*100/float(len(test_y)))\n",
    "    precision.append(p)  \n",
    "    recall.append(r)  \n",
    "\n",
    "print('Accuracy:', sum(accuracy)/len(accuracy))\n",
    "print('10-fold:', accuracy)\n",
    "print('Precision:', sum(precision)/len(precision))\n",
    "print('Recall:', sum(recall)/len(recall))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)\n",
    "print('F-Score:', sum(scores)/len(scores))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump your classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(clf_nb,open(\"Obama_Multinomial_NB\",\"wb\"))\n",
    "pickle.dump(clf_nn_mlp,open(\"Obama_Multi-Layer Perceptron\",\"wb\"))\n",
    "pickle.dump(clf_rfc,open(\"Obama_Random_Forest\",\"wb\"))\n",
    "pickle.dump(clf_svc,open(\"Obama_SVM\",\"wb\"))\n",
    "pickle.dump(clf_voting,open(\"Obama_Weight_Voting\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded_nb = pickle.load(open(\"Obama_Multinomial_NB\",\"rb\"))\n",
    "loaded_nn_mlp = pickle.load(open(\"Obama_Multi-Layer Perceptron\",\"rb\"))\n",
    "loaded_rfc = pickle.load(open(\"Obama_Random_Forest\",\"rb\"))\n",
    "loaded_svc = pickle.load(open(\"Obama_SVM\",\"rb\"))\n",
    "loaded_voting = pickle.load(open(\"Obama_Weight_Voting\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "obamaData_counts = count_vect.fit_transform(obamaData['tweet'])\n",
    "obamaData_tfidf = tfidf_transformer.fit_transform(obamaData_counts)\n",
    "obamaData_labels = obamaData['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.583562608162\n",
      "[[1367  327  274]\n",
      " [ 661  841  468]\n",
      " [ 358  244 1060]]\n",
      "[ 0.5729254   0.59560907  0.58823529]\n",
      "[ 0.69461382  0.42690355  0.6377858 ]\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(loaded_nb,obamaData_counts,obamaData_labels,cv=10)\n",
    "predicted = cross_val_predict(loaded_nb,obamaData_counts,obamaData_labels,cv=10)\n",
    "confusion = confusion_matrix(obamaData_labels, predicted)\n",
    "precision=precision_score(obamaData_labels, predicted, average=None)\n",
    "recall=recall_score(obamaData_labels, predicted, average=None)\n",
    "print(score.mean())\n",
    "print(confusion)\n",
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.561436944269\n",
      "[[1138  518  312]\n",
      " [ 529 1015  426]\n",
      " [ 303  396  963]]\n",
      "[ 0.57766497  0.52617937  0.56613757]\n",
      "[ 0.57825203  0.51522843  0.57942238]\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(loaded_rfc,obamaData_counts,obamaData_labels,cv=10)\n",
    "predicted = cross_val_predict(loaded_rfc,obamaData_counts,obamaData_labels,cv=10)\n",
    "confusion = confusion_matrix(obamaData_labels, predicted)\n",
    "precision=precision_score(obamaData_labels, predicted, average=None)\n",
    "recall=recall_score(obamaData_labels, predicted, average=None)\n",
    "print(score.mean())\n",
    "print(confusion)\n",
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = cross_val_score(loaded_nn_mlp,obamaData_counts,obamaData_labels,cv=10)\n",
    "predicted = cross_val_predict(loaded_nn_mlp,obamaData_counts,obamaData_labels,cv=10)\n",
    "confusion = confusion_matrix(obamaData_labels, predicted)\n",
    "precision=precision_score(obamaData_labels, predicted, average=None)\n",
    "recall=recall_score(obamaData_labels, predicted, average=None)\n",
    "print(score.mean())\n",
    "print(confusion)\n",
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.56927879576\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(loaded_svc,obamaData_counts,obamaData_labels,cv=10)\n",
    "predicted = cross_val_predict(loaded_svc,obamaData_counts,obamaData_labels,cv=10)\n",
    "confusion = confusion_matrix(obamaData_labels, predicted)\n",
    "precision=precision_score(obamaData_labels, predicted, average=None)\n",
    "recall=recall_score(obamaData_labels, predicted, average=None)\n",
    "print(score.mean())\n",
    "print(confusion)\n",
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier - Naive Bayes, Neural Network, Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.604811674873\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(loaded_voting,obamaData_counts,obamaData_labels,cv=10)\n",
    "predicted = cross_val_predict(loaded_voting,obamaData_counts,obamaData_labels,cv=10)\n",
    "confusion = confusion_matrix(obamaData_labels, predicted)\n",
    "precision=precision_score(obamaData_labels, predicted, average=None)\n",
    "recall=recall_score(obamaData_labels, predicted, average=None)\n",
    "print(score.mean())\n",
    "print(confusion)\n",
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clfs = {}\n",
    "\n",
    "# parameters_mlp = {'hidden_layer_sizes' : np.arange(5,12),'solver':['lbgfs'],'activation':['identity','logistic','tanh','relu'],\n",
    "#                  'max_iter':[1500],'alpha':10.0 ** -np.arange(1,7)}\n",
    "# clfs['mlpGrid'] = {'clf' : GridSearchCV(MLPClassifier(),parameters_mlp),'name':'MLP with Grid Search'}\n",
    "\n",
    "# # # 2 SVC \n",
    "# # parameters_svc = {'kernel':['linear','poly','sigmoid','rbf'],'gamma':np.linspace(0.0,2.0,num=21),'C':np.linspace(.5,1.5,num=11)}\n",
    "# # clfs['svcGrid'] = {'clf' : GridSearchCV(SVC(),parameters_svc),'name':'SVC with Grid Search'}\n",
    "\n",
    "# # 3 Random forest\n",
    "# parameters_rfc = {'n_estimators':[20,50,100],'max_depth':[4,None],'max_features':[2,4],\n",
    "#                   'criterion':['gini','entropy'],'min_samples_split': [1, 3, 10],'min_samples_leaf': [1, 3, 10],\n",
    "#                   'bootstrap':[True,False]}\n",
    "# clfs['rfcGrid'] = {'clf': GridSearchCV(RandomForestClassifier(),parameters_rfc),'name':'Random Forest with Grid Search'}\n",
    "\n",
    "# # 4 KNN\n",
    "# parameters_knn = {'n_neighbors':np.arange(3,12),'weights':['distance','uniform']}\n",
    "# clfs['knnGrid'] = {'clf': GridSearchCV(KNeighborsClassifier(),parameters_knn),'name':'KNearest Neighbor with Grid Search'}\n",
    "\n",
    "# # 5 logistic regression\n",
    "# parameters_lg = {'C':[1],'tol':[0.0001],'solver': ['newton-cg','lbfgs'], 'multi_class': ['multinomial']}\n",
    "# clfs['lgGrid'] = {'clf': GridSearchCV(LogisticRegression(),parameters_lg),'name':'Logistic Regression with Grid Search'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for clf in clfs:\n",
    "#     clfs[clf]['score'] = cross_val_score(clfs[clf]['clf'],obamaData_tfidf,obamaData_labels,cv=10)\n",
    "#     print(clfs[clf]['name'] + \" : %0.4f (+/- %0.4f)\" % (clfs[clf]['score'].mean(),clfs[clf]['score'].std()*2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
