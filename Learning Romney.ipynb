{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split,cross_val_score, KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5648\n",
      "5640\n"
     ]
    }
   ],
   "source": [
    "obamaData = pd.read_csv(\"romneyCleanedData.csv\")\n",
    "print(len(obamaData))\n",
    "obamaData.dropna(axis=0,inplace=True)\n",
    "print(len(obamaData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.8191489362\n",
      "10-fold: [56.737588652482266, 56.382978723404257, 58.865248226950357, 56.560283687943262, 58.687943262411345, 57.446808510638299, 57.446808510638299, 57.624113475177303, 59.042553191489361, 59.397163120567377]\n",
      "Precision: [ 0.59904601  0.4883697   0.57072744]\n",
      "Recall: [ 0.86175101  0.26892462  0.29468381]\n",
      "Confusion matrix:\n",
      "[[2491  306   94]\n",
      " [1086  452  141]\n",
      " [ 582  170  318]]\n",
      "F-Score: [ 0.70667681  0.34641231  0.38779276]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "k_fold = KFold(n=len(obamaData), n_folds=10)\n",
    "scores = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "confusion = np.array([[0, 0, 0],[0, 0, 0], [0, 0, 0]])\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = obamaData.iloc[train_indices]['tweet'].values\n",
    "    train_y = obamaData.iloc[train_indices]['label'].values\n",
    "\n",
    "    test_text = obamaData.iloc[test_indices]['tweet'].values\n",
    "    test_y = np.asarray(obamaData.iloc[test_indices]['label'].values, dtype=\"|S6\")\n",
    "\n",
    "    counts = count_vectorizer.fit_transform(train_text)\n",
    "    targets = np.asarray(train_y, dtype=\"|S6\")\n",
    "    classifier.fit(counts, targets)\n",
    "    predictions = classifier.predict(count_vectorizer.transform(test_text))\n",
    "\n",
    "    confusion+= confusion_matrix(test_y, predictions)\n",
    "    p=precision_score(test_y, predictions, average=None)\n",
    "    r=recall_score(test_y, predictions, average=None)\n",
    "    score = 2*p*r/(p+r)\n",
    "    scores.append(score)\n",
    "    accuracy.append((predictions==test_y).sum()*100/float(len(test_y)))\n",
    "    precision.append(p)  \n",
    "    recall.append(r)  \n",
    "\n",
    "print('Accuracy:', sum(accuracy)/len(accuracy))\n",
    "print('10-fold:', accuracy)\n",
    "print('Precision:', sum(precision)/len(precision))\n",
    "print('Recall:', sum(recall)/len(recall))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)\n",
    "print('F-Score:', sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.3510638298\n",
      "10-fold: [57.978723404255319, 55.851063829787236, 59.397163120567377, 58.51063829787234, 58.865248226950357, 60.106382978723403, 58.156028368794324, 58.865248226950357, 56.914893617021278, 58.865248226950357]\n",
      "Precision: [ 0.65714026  0.45965937  0.52448887]\n",
      "Recall: [ 0.73810091  0.42211797  0.41573595]\n",
      "Confusion matrix:\n",
      "[[2134  558  199]\n",
      " [ 765  710  204]\n",
      " [ 350  273  447]]\n",
      "F-Score: [ 0.69495753  0.43971839  0.46251148]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:561: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_nn_MLP = MLPClassifier(solver='sgd', alpha=0.001,hidden_layer_sizes=(50, 10), learning_rate = 'adaptive', random_state=42,activation='tanh')\n",
    "\n",
    "k_fold = KFold(n=len(obamaData), n_folds=10)\n",
    "scores = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "confusion = np.array([[0, 0, 0],[0, 0, 0], [0, 0, 0]])\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = obamaData.iloc[train_indices]['tweet'].values\n",
    "    train_y = obamaData.iloc[train_indices]['label'].values\n",
    "\n",
    "    test_text = obamaData.iloc[test_indices]['tweet'].values\n",
    "    test_y = np.asarray(obamaData.iloc[test_indices]['label'].values, dtype=\"|S6\")\n",
    "\n",
    "    counts = count_vectorizer.fit_transform(train_text)\n",
    "    targets = np.asarray(train_y, dtype=\"|S6\")\n",
    "    clf_nn_MLP.fit(counts, targets)\n",
    "    predictions = clf_nn_MLP.predict(count_vectorizer.transform(test_text))\n",
    "\n",
    "    confusion+= confusion_matrix(test_y, predictions)\n",
    "    p=precision_score(test_y, predictions, average=None)\n",
    "    r=recall_score(test_y, predictions, average=None)\n",
    "    score = 2*p*r/(p+r)\n",
    "    scores.append(score)\n",
    "    accuracy.append((predictions==test_y).sum()*100/float(len(test_y)))\n",
    "    precision.append(p)  \n",
    "    recall.append(r)  \n",
    "\n",
    "print('Accuracy:', sum(accuracy)/len(accuracy))\n",
    "print('10-fold:', accuracy)\n",
    "print('Precision:', sum(precision)/len(precision))\n",
    "print('Recall:', sum(recall)/len(recall))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)\n",
    "print('F-Score:', sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.2872340426\n",
      "10-fold: [57.269503546099294, 56.028368794326241, 59.574468085106382, 57.269503546099294, 57.269503546099294, 57.092198581560282, 55.851063829787236, 58.333333333333336, 58.156028368794324, 56.028368794326241]\n",
      "Precision: [ 0.61085424  0.45061684  0.59155306]\n",
      "Recall: [ 0.7975384   0.34154242  0.3265924 ]\n",
      "Confusion matrix:\n",
      "[[2305  471  115]\n",
      " [ 981  574  124]\n",
      " [ 489  229  352]]\n",
      "F-Score: [ 0.69161312  0.38815871  0.42008199]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rfc = RandomForestClassifier(n_estimators=22,class_weight=\"balanced_subsample\")\n",
    "\n",
    "k_fold = KFold(n=len(obamaData), n_folds=10)\n",
    "scores = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "confusion = np.array([[0, 0, 0],[0, 0, 0], [0, 0, 0]])\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = obamaData.iloc[train_indices]['tweet'].values\n",
    "    train_y = obamaData.iloc[train_indices]['label'].values\n",
    "\n",
    "    test_text = obamaData.iloc[test_indices]['tweet'].values\n",
    "    test_y = np.asarray(obamaData.iloc[test_indices]['label'].values, dtype=\"|S6\")\n",
    "\n",
    "    counts = count_vectorizer.fit_transform(train_text)\n",
    "    targets = np.asarray(train_y, dtype=\"|S6\")\n",
    "    clf_rfc.fit(counts, targets)\n",
    "    predictions = clf_rfc.predict(count_vectorizer.transform(test_text))\n",
    "\n",
    "    confusion+= confusion_matrix(test_y, predictions)\n",
    "    p=precision_score(test_y, predictions, average=None)\n",
    "    r=recall_score(test_y, predictions, average=None)\n",
    "    score = 2*p*r/(p+r)\n",
    "    scores.append(score)\n",
    "    accuracy.append((predictions==test_y).sum()*100/float(len(test_y)))\n",
    "    precision.append(p)  \n",
    "    recall.append(r)  \n",
    "\n",
    "print('Accuracy:', sum(accuracy)/len(accuracy))\n",
    "print('10-fold:', accuracy)\n",
    "print('Precision:', sum(precision)/len(precision))\n",
    "print('Recall:', sum(recall)/len(recall))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)\n",
    "print('F-Score:', sum(scores)/len(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.4893617021\n",
      "10-fold: [58.156028368794324, 53.01418439716312, 56.560283687943262, 57.446808510638299, 56.205673758865245, 55.673758865248224, 54.432624113475178, 57.092198581560282, 58.687943262411345, 57.624113475177303]\n",
      "Precision: [ 0.6469665   0.43993353  0.47752713]\n",
      "Recall: [ 0.72060285  0.38570518  0.42253144]\n",
      "Confusion matrix:\n",
      "[[2083  560  248]\n",
      " [ 786  648  245]\n",
      " [ 352  263  455]]\n",
      "F-Score: [ 0.6814942   0.41021898  0.44733372]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf_svc = LinearSVC(C=0.5,loss=\"hinge\",multi_class=\"ovr\",penalty=\"l2\")\n",
    "\n",
    "k_fold = KFold(n=len(obamaData), n_folds=10)\n",
    "scores = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "confusion = np.array([[0, 0, 0],[0, 0, 0], [0, 0, 0]])\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = obamaData.iloc[train_indices]['tweet'].values\n",
    "    train_y = obamaData.iloc[train_indices]['label'].values\n",
    "\n",
    "    test_text = obamaData.iloc[test_indices]['tweet'].values\n",
    "    test_y = np.asarray(obamaData.iloc[test_indices]['label'].values, dtype=\"|S6\")\n",
    "\n",
    "    counts = count_vectorizer.fit_transform(train_text)\n",
    "    targets = np.asarray(train_y, dtype=\"|S6\")\n",
    "    clf_svc.fit(counts, targets)\n",
    "    predictions = clf_svc.predict(count_vectorizer.transform(test_text))\n",
    "\n",
    "    confusion+= confusion_matrix(test_y, predictions)\n",
    "    p=precision_score(test_y, predictions, average=None)\n",
    "    r=recall_score(test_y, predictions, average=None)\n",
    "    score = 2*p*r/(p+r)\n",
    "    scores.append(score)\n",
    "    accuracy.append((predictions==test_y).sum()*100/float(len(test_y)))\n",
    "    precision.append(p)  \n",
    "    recall.append(r)  \n",
    "\n",
    "print('Accuracy:', sum(accuracy)/len(accuracy))\n",
    "print('10-fold:', accuracy)\n",
    "print('Precision:', sum(precision)/len(precision))\n",
    "print('Recall:', sum(recall)/len(recall))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)\n",
    "print('F-Score:', sum(scores)/len(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    2893\n",
       " 1    2069\n",
       " 0    1680\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.read_csv(\"cleaned files/romneyCleanedData_with_sampling.csv\")\n",
    "new_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
