{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split,cross_val_score, KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6642\n",
      "5648\n",
      "6629\n",
      "5640\n"
     ]
    }
   ],
   "source": [
    "obamaData = pd.read_csv(\"romneyCleanedData_with_sampling.csv\")\n",
    "romneyData = pd.read_csv(\"romneyCleanedData.csv\")\n",
    "print(len(obamaData))\n",
    "print(len(romneyData))\n",
    "obamaData.dropna(axis=0,inplace=True)\n",
    "romneyData.dropna(axis=0,inplace=True)\n",
    "print(len(obamaData))\n",
    "print(len(romneyData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.8723404255\n",
      "10-fold: [58.51063829787234, 55.49645390070922, 57.269503546099294, 56.737588652482266, 59.219858156028366, 59.574468085106382, 56.914893617021278, 58.51063829787234, 58.333333333333336, 58.156028368794324]\n",
      "Precision: [ 0.58595014  0.50396283  0.6291821 ]\n",
      "Recall: [ 0.88945615  0.2350478   0.27562808]\n",
      "Confusion matrix:\n",
      "[[2571  254   66]\n",
      " [1180  395  104]\n",
      " [ 637  135  298]]\n",
      "F-Score: [ 0.70638855  0.3202973   0.38245343]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "count_vectorizer = CountVectorizer(stop_words='english', max_features=1000, analyzer = 'word', ngram_range = (1,2) )\n",
    "tfidf_transformer = TfidfTransformer(use_idf=True)\n",
    "\n",
    "\n",
    "k_fold = KFold(n=len(romneyData), n_folds=10)\n",
    "scores = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "confusion = np.array([[0, 0, 0],[0, 0, 0], [0, 0, 0]])\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = romneyData.iloc[train_indices]['tweet'].values\n",
    "    train_y = romneyData.iloc[train_indices]['label'].values\n",
    "\n",
    "    test_text = romneyData.iloc[test_indices]['tweet'].values\n",
    "    test_y = np.asarray(romneyData.iloc[test_indices]['label'].values, dtype=\"|S6\")\n",
    "\n",
    "    counts = count_vectorizer.fit_transform(train_text)\n",
    "    tfidf_vectors = tfidf_transformer.fit_transform(counts)\n",
    "    targets = np.asarray(train_y, dtype=\"|S6\")\n",
    "    classifier.fit(tfidf_vectors, targets)\n",
    "    \n",
    "    test_counts = count_vectorizer.transform(test_text)\n",
    "    predictions = classifier.predict(tfidf_transformer.transform(test_counts))\n",
    "\n",
    "    confusion+= confusion_matrix(test_y, predictions)\n",
    "    p=precision_score(test_y, predictions, average=None)\n",
    "    r=recall_score(test_y, predictions, average=None)\n",
    "    score = 2*p*r/(p+r)\n",
    "    scores.append(score)\n",
    "    accuracy.append((predictions==test_y).sum()*100/float(len(test_y)))\n",
    "    precision.append(p)  \n",
    "    recall.append(r)  \n",
    "\n",
    "print('Accuracy:', sum(accuracy)/len(accuracy))\n",
    "print('10-fold:', accuracy)\n",
    "print('Precision:', sum(precision)/len(precision))\n",
    "print('Recall:', sum(recall)/len(recall))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)\n",
    "print('F-Score:', sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.6100987455\n",
      "10-fold: [62.594268476621416, 65.460030165912514, 64.25339366515837, 68.929110105580691, 61.085972850678736, 61.990950226244344, 63.951734539969834, 65.309200603318246, 67.571644042232279, 64.954682779456192]\n",
      "Precision: [ 0.66977097  0.47877125  0.71055946]\n",
      "Recall: [ 0.69719294  0.37623404  0.79457718]\n",
      "Confusion matrix:\n",
      "[[2016  525  350]\n",
      " [ 731  632  316]\n",
      " [ 264  160 1635]]\n",
      "F-Score: [ 0.68290638  0.42001473  0.74929254]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:561: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_nn_MLP = MLPClassifier(solver='sgd', alpha=0.001,hidden_layer_sizes=(50, 10), learning_rate = 'adaptive', random_state=42,activation='tanh')\n",
    "\n",
    "k_fold = KFold(n=len(obamaData), n_folds=10)\n",
    "scores = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "confusion = np.array([[0, 0, 0],[0, 0, 0], [0, 0, 0]])\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = obamaData.iloc[train_indices]['tweet'].values\n",
    "    train_y = obamaData.iloc[train_indices]['label'].values\n",
    "\n",
    "    test_text = obamaData.iloc[test_indices]['tweet'].values\n",
    "    test_y = np.asarray(obamaData.iloc[test_indices]['label'].values, dtype=\"|S6\")\n",
    "\n",
    "    counts = count_vectorizer.fit_transform(train_text)\n",
    "    tfidf_vectors = tfidf_transformer(counts)\n",
    "    targets = np.asarray(train_y, dtype=\"|S6\")\n",
    "    clf_nn_MLP.fit(tfidf_vectors, targets)\n",
    "    \n",
    "    test_counts = count_vectorizer.transform(test_text)\n",
    "    predictions = clf_nn_MLP.predict(tfidf_transformer.transform(test_counts))\n",
    "\n",
    "    confusion+= confusion_matrix(test_y, predictions)\n",
    "    p=precision_score(test_y, predictions, average=None)\n",
    "    r=recall_score(test_y, predictions, average=None)\n",
    "    score = 2*p*r/(p+r)\n",
    "    scores.append(score)\n",
    "    accuracy.append((predictions==test_y).sum()*100/float(len(test_y)))\n",
    "    precision.append(p)  \n",
    "    recall.append(r)  \n",
    "\n",
    "print('Accuracy:', sum(accuracy)/len(accuracy))\n",
    "print('10-fold:', accuracy)\n",
    "print('Precision:', sum(precision)/len(precision))\n",
    "print('Recall:', sum(recall)/len(recall))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)\n",
    "print('F-Score:', sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 36.0106382979\n",
      "10-fold: [33.156028368794324, 39.893617021276597, 38.120567375886523, 33.51063829787234, 34.574468085106382, 31.914893617021278, 30.851063829787233, 33.865248226950357, 29.609929078014183, 54.609929078014183]\n",
      "Precision: [ 0.51206908  0.30779092  0.21015976]\n",
      "Recall: [ 0.34617797  0.51220918  0.16216677]\n",
      "Confusion matrix:\n",
      "[[ 995 1460  436]\n",
      " [ 556  860  263]\n",
      " [ 361  533  176]]\n",
      "F-Score: [ 0.39786725  0.37543236  0.18034424]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rfc = RandomForestClassifier(n_estimators=22,class_weight=\"balanced_subsample\")\n",
    "\n",
    "# count_vectorizer_rfc = CountVectorizer(stop_words='english', max_features=500, analyzer = 'word', ngram_range = (1,2) )\n",
    "# tfidf_transformer_rfc = TfidfTransformer(use_idf=True)\n",
    "\n",
    "\n",
    "k_fold = KFold(n=len(romneyData), n_folds=10)\n",
    "scores = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "confusion = np.array([[0, 0, 0],[0, 0, 0], [0, 0, 0]])\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = romneyData.iloc[train_indices]['tweet'].values\n",
    "    train_y = romneyData.iloc[train_indices]['label'].values\n",
    "\n",
    "    test_text = romneyData.iloc[test_indices]['tweet'].values\n",
    "    test_y = np.asarray(romneyData.iloc[test_indices]['label'].values, dtype=\"|S6\")\n",
    "\n",
    "    counts_rfc = count_vectorizer.fit_transform(train_text)\n",
    "    tfidf_vectors_rfc = tfidf_transformer.transform(counts_rfc)\n",
    "    targets = np.asarray(train_y, dtype=\"|S6\")\n",
    "    \n",
    "    test_counts_rfc = count_vectorizer.transform(test_text)\n",
    "    test_tfidf_vector_rfc = tfidf_transformer.transform(test_counts)\n",
    "    clf_rfc.fit(tfidf_vectors_rfc, targets)\n",
    "    predictions = clf_rfc.predict(test_tfidf_vector_rfc)\n",
    "\n",
    "    confusion+= confusion_matrix(test_y, predictions)\n",
    "    p=precision_score(test_y, predictions, average=None)\n",
    "    r=recall_score(test_y, predictions, average=None)\n",
    "    score = 2*p*r/(p+r)\n",
    "    scores.append(score)\n",
    "    accuracy.append((predictions==test_y).sum()*100/float(len(test_y)))\n",
    "    precision.append(p)  \n",
    "    recall.append(r)  \n",
    "\n",
    "print('Accuracy:', sum(accuracy)/len(accuracy))\n",
    "print('10-fold:', accuracy)\n",
    "print('Precision:', sum(precision)/len(precision))\n",
    "print('Recall:', sum(recall)/len(recall))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)\n",
    "print('F-Score:', sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
